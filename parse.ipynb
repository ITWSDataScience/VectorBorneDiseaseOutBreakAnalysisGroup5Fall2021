{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/promed_Congo-Crimean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../Epitator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epitator.annotator import AnnoDoc\n",
    "from epitator.count_annotator import CountAnnotator\n",
    "from epitator.date_annotator import DateAnnotator\n",
    "from epitator.geoname_annotator import GeonameAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from typing import List\n",
    "\n",
    "# setup our BART transformer summarization model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to summarize an input text with the BART model\n",
    "def summarizer(text: str) -> str:\n",
    "    input_ids = tokenizer(text, return_tensors='pt', max_length=1024, padding=True, truncation=True)['input_ids']\n",
    "    summary_ids = model.generate(input_ids.cuda())\n",
    "    summary = ''.join([tokenizer.decode(s) for s in summary_ids])\n",
    "    summary = summary.replace('<s>', '').replace('</s>', '')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to strip html tags from a string (needed for better accuracy)\n",
    "def clean_html(raw_html: str, strip=True) -> str:\n",
    "  cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "  clean = re.sub(cleanr, '', raw_html)\n",
    "  if strip:\n",
    "    clean = re.sub(r'\\W+', ' ', clean)\n",
    "  return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract the date the article was published from the header/title\n",
    "def extract_publish_date(text: str) -> str:\n",
    "    return re.search(r'[0-9]{4}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1])', text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASES = [\n",
    "    'Chagas disease',\n",
    "    'Chikungunya',\n",
    "    'Congo-Crimean haemorrhagic fever',\n",
    "    'Dengue',\n",
    "    'Dracunculiasis',\n",
    "    'guinea-worm disease'\n",
    "    'Human African trypanosomiasis',\n",
    "    'Leishmaniasis',\n",
    "    'Lymphatic filariasis',\n",
    "    'Lyme disease',\n",
    "    'Malaria',\n",
    "    'Onchocerciasis',\n",
    "    'Schistosomiasis',\n",
    "    'Yellow fever',\n",
    "]\n",
    "# helper function to extract type of vector-borne disease from data\n",
    "def extract_disease(txt: str) -> str:\n",
    "    txt = txt.lower()\n",
    "    for d in DISEASES:\n",
    "        if d.lower() in txt:\n",
    "            return d\n",
    "\n",
    "    return 'Not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts location names/admin codes/lat/lng, case and death counts, and date ranges from the input string\n",
    "# uses epitator since it already trained rules for extracting medical/infectious disease data\n",
    "def epitator_extract(txt, max_ents=1):\n",
    "    # input string and add annotators\n",
    "    doc = AnnoDoc(txt)\n",
    "    doc.add_tiers(GeonameAnnotator())\n",
    "    doc.add_tiers(CountAnnotator())\n",
    "    doc.add_tiers(DateAnnotator())\n",
    "\n",
    "    # extract geographic data\n",
    "    geos = doc.tiers[\"geonames\"].spans\n",
    "    geo_admin1s = [x.geoname.admin1_code for x in geos]\n",
    "    geo_admin2s = [x.geoname.admin2_code for x in geos]\n",
    "    geo_admin3s = [x.geoname.admin3_code for x in geos]\n",
    "    geo_admin4s = [x.geoname.admin4_code for x in geos]\n",
    "    geo_names = [x.geoname.name for x in geos]\n",
    "    geo_lats = [x.geoname.latitude for x in geos]\n",
    "    geo_lons = [x.geoname.longitude for x in geos]\n",
    "\n",
    "    # extract case counts and death counts\n",
    "    counts = doc.tiers[\"counts\"].spans\n",
    "    cases_counts = [x.metadata['count'] for x in counts if 'case' in x.metadata['attributes'] and 'death' not in x.metadata['attributes']]\n",
    "    cases_tags = [x.metadata['attributes'] for x in counts if 'case' in x.metadata['attributes'] and 'death' not in x.metadata['attributes']]\n",
    "    death_counts = [x.metadata['count'] for x in counts if 'death' in x.metadata['attributes']]\n",
    "    death_tags = [x.metadata['attributes'] for x in counts if 'death' in x.metadata['attributes']]\n",
    "\n",
    "    # extract the date range\n",
    "    dates = doc.tiers[\"dates\"].spans\n",
    "    dates_start = [pd.to_datetime(x.metadata[\"datetime_range\"][0], errors='coerce') for x in dates]\n",
    "    dates_end = [pd.to_datetime(x.metadata[\"datetime_range\"][1], errors='coerce') for x in dates]\n",
    "\n",
    "    # return only max_ents entities from the extracted lists\n",
    "    # currently set to the first result for each list, since that is usually the most important one\n",
    "    # and other ones can be filler/garbage data\n",
    "    return pd.Series([ \n",
    "        geo_admin1s[:max_ents],\n",
    "        geo_admin2s[:max_ents],\n",
    "        geo_admin3s[:max_ents],\n",
    "        geo_admin4s[:max_ents],\n",
    "        geo_names[:max_ents],\n",
    "        geo_lats[:max_ents],\n",
    "        geo_lons[:max_ents],\n",
    "        cases_counts[:max_ents],\n",
    "        cases_tags[:max_ents],\n",
    "        death_counts[:max_ents],\n",
    "        death_tags[:max_ents],\n",
    "        dates_start[:max_ents],\n",
    "        dates_end[:max_ents],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n",
      "Unnamed: 0\n",
      "id\n",
      "title\n",
      "zoom_lat\n",
      "zoom_lon\n",
      "zoom_level\n",
      "alert_id\n",
      "feed_id\n",
      "summary\n",
      "issue_date\n",
      "load_date\n",
      "incident_date\n",
      "descr\n",
      "alert_tag_id\n",
      "dup_count\n",
      "dup_of\n",
      "unique_string\n",
      "info_hash\n",
      "submitted_by\n",
      "reviewed\n",
      "search_string_id\n",
      "content\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>zoom_lat</th>\n",
       "      <th>zoom_lon</th>\n",
       "      <th>zoom_level</th>\n",
       "      <th>alert_id</th>\n",
       "      <th>feed_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>issue_date</th>\n",
       "      <th>...</th>\n",
       "      <th>descr</th>\n",
       "      <th>alert_tag_id</th>\n",
       "      <th>dup_count</th>\n",
       "      <th>dup_of</th>\n",
       "      <th>unique_string</th>\n",
       "      <th>info_hash</th>\n",
       "      <th>submitted_by</th>\n",
       "      <th>reviewed</th>\n",
       "      <th>search_string_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8546572</td>\n",
       "      <td>8546572</td>\n",
       "      <td>['Crimean-Congo hem. fever - Asia (07): Iraq, ...</td>\n",
       "      <td>33.048031</td>\n",
       "      <td>43.772129</td>\n",
       "      <td>5</td>\n",
       "      <td>8546572</td>\n",
       "      <td>1</td>\n",
       "      <td>PRO/AH/EDR&gt; Crimean-Congo hem. fever - Asia (0...</td>\n",
       "      <td>2021-07-30 06:49:07</td>\n",
       "      <td>...</td>\n",
       "      <td>Today, Saturday (24 Jul 2021), the Veterinary ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.021073e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRIMEAN-CONGO HEMORRHAGIC FEVER - ASIA (07): I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                                              title  \\\n",
       "0     8546572  8546572  ['Crimean-Congo hem. fever - Asia (07): Iraq, ...   \n",
       "\n",
       "    zoom_lat   zoom_lon  zoom_level  alert_id  feed_id  \\\n",
       "0  33.048031  43.772129           5   8546572        1   \n",
       "\n",
       "                                             summary           issue_date  \\\n",
       "0  PRO/AH/EDR> Crimean-Congo hem. fever - Asia (0...  2021-07-30 06:49:07   \n",
       "\n",
       "   ...                                              descr  alert_tag_id  \\\n",
       "0  ...  Today, Saturday (24 Jul 2021), the Veterinary ...           NaN   \n",
       "\n",
       "  dup_count  dup_of  unique_string  info_hash  submitted_by reviewed  \\\n",
       "0         0     NaN   2.021073e+07        NaN       14321.0      NaN   \n",
       "\n",
       "   search_string_id                                            content  \n",
       "0               NaN  CRIMEAN-CONGO HEMORRHAGIC FEVER - ASIA (07): I...  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH, sep='\\t')\n",
    "print(len(df))\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHAVAR~1\\AppData\\Local\\Temp/ipykernel_18492/4185879499.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'publish_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_publish_date\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# add date column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummarizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'disease'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_disease\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4354\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \"\"\"\n\u001b[1;32m-> 4356\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4358\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1090\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1093\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newenv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CHAVAR~1\\AppData\\Local\\Temp/ipykernel_18492/1601418552.py\u001b[0m in \u001b[0;36mextract_publish_date\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# helper function to extract the date the article was published from the header/title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_publish_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[0-9]{4}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1])'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df['publish_date'] = df['title'].apply(extract_publish_date) # add date column\n",
    "df['title'] = df['title'].progress_apply(clean_html)\n",
    "df['body'] = df['content'].progress_apply(clean_html)\n",
    "df['summary'] = df['body'].progress_apply(summarizer)\n",
    "df['disease'] = df['body'].progress_apply(extract_disease)\n",
    "df[['admin1_code',\n",
    "'admin2_code',\n",
    "'admin3_code',\n",
    "'admin4_code',\n",
    "'location_name',\n",
    "'location_lat',\n",
    "'location_lon',\n",
    "'cases',\n",
    "'cases_tags',\n",
    "'deaths',\n",
    "'deaths_tags',\n",
    "'dates_start',\n",
    "'dates_end',]] = df['summary'].progress_apply(epitator_extract)\n",
    "df = df.applymap(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x)\n",
    "df = df.applymap(lambda y: pd.NA if isinstance(y, (list, str)) and len(y) == 0 else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATASET_PATH[:-4]+'_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
